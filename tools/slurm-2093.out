Sat Feb 11 23:30:19 2023       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 515.86.01    Driver Version: 515.86.01    CUDA Version: 11.7     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:87:00.0 Off |                  Off |
| N/A   28C    P0    54W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM...  On   | 00000000:90:00.0 Off |                  Off |
| N/A   26C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM...  On   | 00000000:B7:00.0 Off |                  Off |
| N/A   26C    P0    51W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA A100-SXM...  On   | 00000000:BD:00.0 Off |                  Off |
| N/A   27C    P0    53W / 400W |      0MiB / 40960MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2021 NVIDIA Corporation
Built on Thu_Nov_18_09:45:30_PST_2021
Cuda compilation tools, release 11.5, V11.5.119
Build cuda_11.5.r11.5/compiler.30672275_0
/var/spool/slurm/d/job02093/slurm_script: line 30: cd: /home/cl522/github_repo/mm_selfsup/tools: No such file or directory
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launch.py:178: FutureWarning: The module torch.distributed.launch is deprecated
and will be removed in future. Use torchrun.
Note that --use_env is set by default in torchrun.
If your script expects `--local_rank` argument to be set, please
change it to read from `os.environ['LOCAL_RANK']` instead. See 
https://pytorch.org/docs/stable/distributed.html#launch-utility for 
further instructions

  warnings.warn(
WARNING:torch.distributed.run:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/cl522/github_repo/my_mmselfsup/mmselfsup/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
/home/cl522/github_repo/my_mmselfsup/mmselfsup/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
/home/cl522/github_repo/my_mmselfsup/mmselfsup/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
/home/cl522/github_repo/my_mmselfsup/mmselfsup/utils/setup_env.py:42: UserWarning: Setting MKL_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed.
  warnings.warn(
2023-02-11 23:30:26,116 - mmselfsup - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.11 (main, Mar 29 2022, 19:08:29) [GCC 7.5.0]
CUDA available: True
GPU 0,1,2,3: NVIDIA A100-SXM4-40GB
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 11.5, V11.5.119
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0
PyTorch: 1.11.0
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

TorchVision: 0.12.0
OpenCV: 4.7.0
MMCV: 1.7.1
MMCV Compiler: GCC 9.3
MMCV CUDA Compiler: 11.3
MMSelfSup: 0.10.1+42b1b79
------------------------------------------------------------

2023-02-11 23:30:26,764 - mmselfsup - INFO - Distributed training: True
2023-02-11 23:30:27,328 - mmselfsup - INFO - Config:
model = dict(
    type='BarlowTwins',
    backbone=dict(
        type='ResNet',
        depth=50,
        in_channels=3,
        out_indices=[4],
        norm_cfg=dict(type='SyncBN'),
        zero_init_residual=True),
    neck=dict(
        type='NonLinearNeck',
        in_channels=2048,
        hid_channels=8192,
        out_channels=8192,
        num_layers=3,
        with_last_bn=False,
        with_last_bn_affine=False,
        with_avg_pool=True,
        init_cfg=dict(
            type='Kaiming', distribution='uniform', layer=['Linear'])),
    head=dict(type='LatentCrossCorrelationHead', in_channels=8192))
data_source = 'CXR'
dataset_type_mimic = 'MultiViewDatasetMIMIC'
dataset_type_cxr14 = 'MultiViewDatasetNIH'
dataset_type_cxp = 'MultiViewDatasetCXP'
dataset_type_pdc = 'MultiViewDatasetPDC'
img_norm_cfg = dict(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
train_pipeline1 = [
    dict(
        type='Normalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='RandomResizedCrop', size=224, interpolation=3),
    dict(type='RandomHorizontalFlip')
]
train_pipeline2 = [
    dict(
        type='Normalize',
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]),
    dict(type='RandomResizedCrop', size=224, interpolation=3),
    dict(type='RandomHorizontalFlip')
]
prefetch = False
data = dict(
    samples_per_gpu=256,
    workers_per_gpu=8,
    train=[
        dict(
            type='MultiViewDatasetPDC',
            data_source=dict(type='CXR', data_prefix='cxr', ann_file='cxr'),
            num_views=[1, 1],
            pipelines=[[{
                'type': 'Normalize',
                'mean': [0.485, 0.456, 0.406],
                'std': [0.229, 0.224, 0.225]
            }, {
                'type': 'RandomResizedCrop',
                'size': 224,
                'interpolation': 3
            }, {
                'type': 'RandomHorizontalFlip'
            }],
                       [{
                           'type': 'Normalize',
                           'mean': [0.485, 0.456, 0.406],
                           'std': [0.229, 0.224, 0.225]
                       }, {
                           'type': 'RandomResizedCrop',
                           'size': 224,
                           'interpolation': 3
                       }, {
                           'type': 'RandomHorizontalFlip'
                       }]],
            prefetch=False),
        dict(
            type='MultiViewDatasetNIH',
            data_source=dict(type='CXR', data_prefix='cxr', ann_file='cxr'),
            num_views=[1, 1],
            pipelines=[[{
                'type': 'Normalize',
                'mean': [0.485, 0.456, 0.406],
                'std': [0.229, 0.224, 0.225]
            }, {
                'type': 'RandomResizedCrop',
                'size': 224,
                'interpolation': 3
            }, {
                'type': 'RandomHorizontalFlip'
            }],
                       [{
                           'type': 'Normalize',
                           'mean': [0.485, 0.456, 0.406],
                           'std': [0.229, 0.224, 0.225]
                       }, {
                           'type': 'RandomResizedCrop',
                           'size': 224,
                           'interpolation': 3
                       }, {
                           'type': 'RandomHorizontalFlip'
                       }]],
            prefetch=False),
        dict(
            type='MultiViewDatasetCXP',
            data_source=dict(type='CXR', data_prefix='cxr', ann_file='cxr'),
            num_views=[1, 1],
            pipelines=[[{
                'type': 'Normalize',
                'mean': [0.485, 0.456, 0.406],
                'std': [0.229, 0.224, 0.225]
            }, {
                'type': 'RandomResizedCrop',
                'size': 224,
                'interpolation': 3
            }, {
                'type': 'RandomHorizontalFlip'
            }],
                       [{
                           'type': 'Normalize',
                           'mean': [0.485, 0.456, 0.406],
                           'std': [0.229, 0.224, 0.225]
                       }, {
                           'type': 'RandomResizedCrop',
                           'size': 224,
                           'interpolation': 3
                       }, {
                           'type': 'RandomHorizontalFlip'
                       }]],
            prefetch=False),
        dict(
            type='MultiViewDatasetMIMIC',
            data_source=dict(type='CXR', data_prefix='cxr', ann_file='cxr'),
            num_views=[1, 1],
            pipelines=[[{
                'type': 'Normalize',
                'mean': [0.485, 0.456, 0.406],
                'std': [0.229, 0.224, 0.225]
            }, {
                'type': 'RandomResizedCrop',
                'size': 224,
                'interpolation': 3
            }, {
                'type': 'RandomHorizontalFlip'
            }],
                       [{
                           'type': 'Normalize',
                           'mean': [0.485, 0.456, 0.406],
                           'std': [0.229, 0.224, 0.225]
                       }, {
                           'type': 'RandomResizedCrop',
                           'size': 224,
                           'interpolation': 3
                       }, {
                           'type': 'RandomHorizontalFlip'
                       }]],
            prefetch=False)
    ])
optimizer = dict(
    type='LARS',
    lr=1.6,
    weight_decay=1e-06,
    momentum=0.9,
    paramwise_options=dict({
        '(bn|gn)(\d+)?.(weight|bias)':
        dict(weight_decay=0, lr_mult=0.024, lars_exclude=True),
        'bias':
        dict(weight_decay=0, lr_mult=0.024, lars_exclude=True),
        'downsample.1':
        dict(weight_decay=0, lr_mult=0.024, lars_exclude=True)
    }))
optimizer_config = dict()
lr_config = dict(
    policy='CosineAnnealing',
    min_lr=0.0016,
    warmup='linear',
    warmup_iters=10,
    warmup_ratio=0.00016,
    warmup_by_epoch=True,
    by_epoch=False)
runner = dict(type='EpochBasedRunner', max_epochs=50)
checkpoint_config = dict(interval=10, max_keep_ckpts=3)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
dist_params = dict(backend='nccl')
cudnn_benchmark = True
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
persistent_workers = True
opencv_num_threads = 0
mp_start_method = 'fork'
work_dir = '/home/cl522/github_repo/mm_selfsup/tools/res50_allCXR'
auto_resume = False
gpu_ids = range(0, 4)

2023-02-11 23:30:27,328 - mmselfsup - INFO - Set random seed to 0, deterministic: False
2023-02-11 23:30:28,307 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-11 23:30:28,311 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-11 23:30:28,322 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-11 23:30:28,342 - mmcv - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': ['Conv2d']}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-11 23:30:28,448 - mmcv - INFO - initialize NonLinearNeck with init_cfg {'type': 'Kaiming', 'distribution': 'uniform', 'layer': ['Linear']}
2023-02-11 23:30:28,452 - mmcv - INFO - initialize NonLinearNeck with init_cfg {'type': 'Kaiming', 'distribution': 'uniform', 'layer': ['Linear']}
2023-02-11 23:30:28,463 - mmcv - INFO - initialize NonLinearNeck with init_cfg {'type': 'Kaiming', 'distribution': 'uniform', 'layer': ['Linear']}
2023-02-11 23:30:28,483 - mmcv - INFO - initialize NonLinearNeck with init_cfg {'type': 'Kaiming', 'distribution': 'uniform', 'layer': ['Linear']}
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,154 - mmcv - INFO - 
backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn3.weight - torch.Size([256]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,155 - mmcv - INFO - 
backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.0.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn3.weight - torch.Size([512]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,156 - mmcv - INFO - 
backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,157 - mmcv - INFO - 
backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn3.weight - torch.Size([1024]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,158 - mmcv - INFO - 
backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn3.weight - torch.Size([2048]): 
Initialized by user-defined `init_weights` in ResNet  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.fc0.weight - torch.Size([8192, 2048]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =uniform, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.bn0.weight - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.bn0.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.fc1.weight - torch.Size([8192, 8192]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =uniform, bias=0 
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.bn1.weight - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.bn1.bias - torch.Size([8192]): 
The value is the same before and after calling `init_weights` of BarlowTwins  
 
2023-02-11 23:30:29,159 - mmcv - INFO - 
neck.fc2.weight - torch.Size([8192, 8192]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =uniform, bias=0 
 
-------
checking cfg!!!
cfg is list or tuple
-------
checking cfg!!!
{'type': 'MultiViewDatasetPDC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torchvision/transforms/transforms.py:890: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
-------
checking cfg!!!
{'type': 'MultiViewDatasetNIH', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetCXP', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetMIMIC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
cfg is list or tuple
-------
checking cfg!!!
{'type': 'MultiViewDatasetPDC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torchvision/transforms/transforms.py:890: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
-------
checking cfg!!!
{'type': 'MultiViewDatasetNIH', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetCXP', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetMIMIC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
cfg is list or tuple
-------
checking cfg!!!
{'type': 'MultiViewDatasetPDC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torchvision/transforms/transforms.py:890: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
-------
checking cfg!!!
{'type': 'MultiViewDatasetNIH', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetCXP', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetMIMIC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
cfg is list or tuple
-------
checking cfg!!!
{'type': 'MultiViewDatasetPDC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torchvision/transforms/transforms.py:890: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
-------
checking cfg!!!
{'type': 'MultiViewDatasetNIH', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetCXP', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
-------
checking cfg!!!
{'type': 'MultiViewDatasetMIMIC', 'data_source': {'type': 'CXR', 'data_prefix': 'cxr', 'ann_file': 'cxr'}, 'num_views': [1, 1], 'pipelines': [[{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}], [{'type': 'Normalize', 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225]}, {'type': 'RandomResizedCrop', 'size': 224, 'interpolation': 3}, {'type': 'RandomHorizontalFlip'}]], 'prefetch': False}
paramwise_options --                                     backbone.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.downsample.1.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.0.downsample.1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.downsample.1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer1.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer1.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer1.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.downsample.1.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.0.downsample.1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.downsample.1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer2.3.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer2.3.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer2.3.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.downsample.1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.0.downsample.1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.downsample.1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.3.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.3.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.3.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.4.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.4.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.4.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer3.5.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer3.5.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer3.5.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.downsample.1.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.0.downsample.1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.downsample.1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.0.downsample.1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.1.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.1.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.1.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn1.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn1.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn1.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn1.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn2.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn2.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn2.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn2.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn2.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn2.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn3.weight: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn3.weight: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn3.weight: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn3.bias: lars_exclude=True
paramwise_options --                                     backbone.layer4.2.bn3.bias: weight_decay=0
paramwise_options --                                     backbone.layer4.2.bn3.bias: lr=0.038400000000000004
paramwise_options --                                     backbone.layer4.2.bn3.bias: lars_exclude=True
paramwise_options --                                     neck.bn0.weight: weight_decay=0
paramwise_options --                                     neck.bn0.weight: lr=0.038400000000000004
paramwise_options --                                     neck.bn0.weight: lars_exclude=True
paramwise_options --                                     neck.bn0.bias: weight_decay=0
paramwise_options --                                     neck.bn0.bias: lr=0.038400000000000004
paramwise_options --                                     neck.bn0.bias: lars_exclude=True
paramwise_options --                                     neck.bn0.bias: weight_decay=0
paramwise_options --                                     neck.bn0.bias: lr=0.038400000000000004
paramwise_options --                                     neck.bn0.bias: lars_exclude=True
paramwise_options --                                     neck.bn1.weight: weight_decay=0
paramwise_options --                                     neck.bn1.weight: lr=0.038400000000000004
paramwise_options --                                     neck.bn1.weight: lars_exclude=True
paramwise_options --                                     neck.bn1.bias: weight_decay=0
paramwise_options --                                     neck.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     neck.bn1.bias: lars_exclude=True
paramwise_options --                                     neck.bn1.bias: weight_decay=0
paramwise_options --                                     neck.bn1.bias: lr=0.038400000000000004
paramwise_options --                                     neck.bn1.bias: lars_exclude=True
2023-02-11 23:30:34,796 - mmselfsup - INFO - Start running, host: cl522@ese-hivemind, work_dir: /home/cl522/github_repo/mm_selfsup/tools/res50_allCXR
2023-02-11 23:30:34,796 - mmselfsup - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(ABOVE_NORMAL) DistOptimizerHook                  
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) CosineAnnealingLrUpdaterHook       
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) DistOptimizerHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) DistSamplerSeedHook                
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-11 23:30:34,796 - mmselfsup - INFO - workflow: [('train', 1)], max: 50 epochs
2023-02-11 23:30:34,796 - mmselfsup - INFO - Checkpoints will be saved to /home/cl522/github_repo/mm_selfsup/tools/res50_allCXR by HardDiskBackend.
Traceback (most recent call last):
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 200, in <module>
    main()
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 190, in main
    train_model(
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/apis/train.py", line 216, in train_model
    runner.run(data_loaders, cfg.workflow)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 136, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 53, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 31, in run_iter
    outputs = self.model.train_step(data_batch, self.optimizer,
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/parallel/distributed.py", line 63, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 132, in train_step
    losses = self(**data)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py", line 119, in new_func
    return old_func(*args, **kwargs)
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 62, in forward
    return self.forward_train(img, **kwargs)
TypeError: forward_train() got an unexpected keyword argument 'label'
Traceback (most recent call last):
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 200, in <module>
    main()
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 190, in main
    train_model(
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/apis/train.py", line 216, in train_model
    runner.run(data_loaders, cfg.workflow)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 136, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 53, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 31, in run_iter
    outputs = self.model.train_step(data_batch, self.optimizer,
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/parallel/distributed.py", line 63, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 132, in train_step
    losses = self(**data)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py", line 119, in new_func
    return old_func(*args, **kwargs)
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 62, in forward
    return self.forward_train(img, **kwargs)
TypeError: forward_train() got an unexpected keyword argument 'label'
Traceback (most recent call last):
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 200, in <module>
    main()
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 190, in main
    train_model(
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/apis/train.py", line 216, in train_model
    runner.run(data_loaders, cfg.workflow)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 136, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 53, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 31, in run_iter
    outputs = self.model.train_step(data_batch, self.optimizer,
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/parallel/distributed.py", line 63, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 132, in train_step
    losses = self(**data)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py", line 119, in new_func
    return old_func(*args, **kwargs)
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 62, in forward
    return self.forward_train(img, **kwargs)
TypeError: forward_train() got an unexpected keyword argument 'label'
Traceback (most recent call last):
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 200, in <module>
    main()
  File "/home/cl522/github_repo/my_mmselfsup/tools/train.py", line 190, in main
    train_model(
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/apis/train.py", line 216, in train_model
    runner.run(data_loaders, cfg.workflow)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 136, in run
    epoch_runner(data_loaders[i], **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 53, in train
    self.run_iter(data_batch, train_mode=True, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/epoch_based_runner.py", line 31, in run_iter
    outputs = self.model.train_step(data_batch, self.optimizer,
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/parallel/distributed.py", line 63, in train_step
    output = self.module.train_step(*inputs[0], **kwargs[0])
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 132, in train_step
    losses = self(**data)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/mmcv/runner/fp16_utils.py", line 119, in new_func
    return old_func(*args, **kwargs)
  File "/home/cl522/github_repo/my_mmselfsup/mmselfsup/models/algorithms/base.py", line 62, in forward
    return self.forward_train(img, **kwargs)
TypeError: forward_train() got an unexpected keyword argument 'label'
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 295, in rebuild_storage_fd
    fd = df.detach()
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/connection.py", line 507, in Client
    c = SocketClient(address)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/connection.py", line 635, in SocketClient
    s.connect(address)
ConnectionRefusedError: [Errno 111] Connection refused
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/threading.py", line 973, in _bootstrap_inner
    self.run()
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/threading.py", line 910, in run
    self._target(*self._args, **self._kwargs)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/utils/data/_utils/pin_memory.py", line 28, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/queues.py", line 122, in get
    return _ForkingPickler.loads(res)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/multiprocessing/reductions.py", line 295, in rebuild_storage_fd
    fd = df.detach()
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/resource_sharer.py", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/resource_sharer.py", line 86, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/connection.py", line 507, in Client
    c = SocketClient(address)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/multiprocessing/connection.py", line 635, in SocketClient
    s.connect(address)
ConnectionRefusedError: [Errno 111] Connection refused
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 2321145 closing signal SIGTERM
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 2321146) of binary: /home/cl522/miniconda3/envs/mmself/bin/python
Traceback (most recent call last):
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launch.py", line 193, in <module>
    main()
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in main
    launch(args)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launch.py", line 174, in launch
    run(args)
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/run.py", line 715, in run
    elastic_launch(
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 131, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/cl522/miniconda3/envs/mmself/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
[1]:
  time      : 2023-02-11_23:31:30
  host      : hivemind
  rank      : 2 (local_rank: 2)
  exitcode  : 1 (pid: 2321147)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
[2]:
  time      : 2023-02-11_23:31:30
  host      : hivemind
  rank      : 3 (local_rank: 3)
  exitcode  : 1 (pid: 2321148)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2023-02-11_23:31:30
  host      : hivemind
  rank      : 1 (local_rank: 1)
  exitcode  : 1 (pid: 2321146)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
